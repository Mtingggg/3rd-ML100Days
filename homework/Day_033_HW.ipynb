{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請觀看李宏毅教授以神奇寶貝進化 CP 值預測的範例，解說何謂機器學習與過擬合。並回答以下問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[youtube](https://www.youtube.com/watch?v=fegAeph9UaA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 模型的泛化能力 (generalization) 是指什麼？ \n",
    "### 2. 分類問題與回歸問題分別可用的目標函數有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.generalization指的是模型樣本外預測的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "### 迴歸問題：mae(L1 loss), mse(l2 loss), Huber\n",
    "#### 如果我們最小化 MSE 來對所有的樣本點只給出一個預測值，那麼這個值一定是所有目標值的平均值。但如果是最小化 MAE，那麼這個值，則會是所有樣本點目標值的中位數。眾所周知，對異常值而言，中位數比均值更加魯棒，因此 MAE 對於異常值也比 MSE 更穩定，然而 MAE 存在一個嚴重的問題（特別是對於神經網絡）：更新的梯度始終相同\n",
    "二者兼有的問題是：在某些情況下，上述兩種損失函數都不能滿足需求。例如，若數據中 90% 的樣本對應的目標值為 150，剩下 10% 在 0 到 30 之間。那麼使用 MAE 作為損失函數的模型可能會忽視 10% 的異常點，而對所有樣本的預測值都為 150。\n",
    "\n",
    "這是因為模型會按中位數來預測。而使用 MSE 的模型則會給出很多介於 0 到 30 的預測值，因為模型會向異常點偏移。上述兩種結果在許多商業場景中都是不可取的。因此出現了Huber的損失函數，當 Huber 損失在 [0-δ,0+δ] 之間時，等價為 MSE，而在 [-∞,δ] 和 [δ,+∞] 時為 MAE。Huber 損失的問題是我們可能需要不斷調整超參數 delta。\n",
    "### 分類問題：entropy,gini index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
